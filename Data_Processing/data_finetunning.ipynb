{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c61ef98",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:white;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<h2>Data processing for Fine-tune</h2>\n",
    "This Jupyter notebook is focused on processing the original dataset, which has been extracted from manually corrected file templates. The primary task involves calculating the ratios of '1's within this dataset. Based on these calculations, we filter out items that predominantly consist of '1's, specifically dropping any items where '1's constitute more than 80% of the data. The final step in this notebook is the creation of a JSON file, meticulously formatted to facilitate the fine-tuning of our model. This process ensures that our dataset is optimally prepared for the fine-tuning phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bc6f270-982f-439d-9b3a-f85320926cef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c390cf7",
   "metadata": {},
   "source": [
    "Calcualte the ratio's of 1s of the origianal dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ef3ca-960c-4263-a925-582733be5b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize counter for 1s\n",
    "total_count_1s = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Summing up the count of 1s for  all components\n",
    "for component in components:\n",
    "    true_labels = filtered_df[component].values\n",
    "    total_count_1s += np.count_nonzero(true_labels == 1)\n",
    "    total_samples += len(true_labels)\n",
    "\n",
    "# Calculating the ratio of 1s to the dataset\n",
    "ratio_of_1s = total_count_1s / total_samples if total_samples != 0 else 0\n",
    "\n",
    "# Print the ratio of 1s of the dataset\n",
    "print(f\"Ratio of 1s across all components: {ratio_of_1s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88a4a6",
   "metadata": {},
   "source": [
    "Drop all the audio files where 80% of the sampels are '1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c621e-97dd-46cd-a510-884c94bd43c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=filtered_df\n",
    "# Calculate the ratio of '1's for each row\n",
    "df['1_ratio'] = df.iloc[:, 1:].sum(axis=1) / (df.shape[1] - 1)  # Exclude 'File' column\n",
    "\n",
    "# Remove rows where '1_ratio' > 0.8\n",
    "df = df[df['1_ratio'] <= 0.8]\n",
    "\n",
    "# Drop the '1_ratio' column if you no longer need it\n",
    "df = df.drop(columns=['1_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71d3910",
   "metadata": {},
   "source": [
    "Recalculate the ratio of '1's for the new filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826d835-974b-4ddc-bbe4-b56c0b9edc53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize counter for 1s\n",
    "total_count_1s = 0\n",
    "total_samples = 0\n",
    "\n",
    "# Summing up the count of 1s for  all components\n",
    "for component in components:\n",
    "    true_labels = filtered_df[component].values\n",
    "    total_count_1s += np.count_nonzero(true_labels == 1)\n",
    "    total_samples += len(true_labels)\n",
    "\n",
    "# Calculating the ratio of 1s to the dataset\n",
    "ratio_of_1s = total_count_1s / total_samples if total_samples != 0 else 0\n",
    "\n",
    "# Print the ratio of 1s of the dataset\n",
    "print(f\"Ratio of 1s across all components: {ratio_of_1s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9c6e7",
   "metadata": {},
   "source": [
    "\n",
    "Set up all the queries, incorporating the desired output and evaluation criteria for each item, along with the transcription of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ba3f394-1169-4619-8aa3-2a423647fe62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_acogidaCorporativa (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Emplea saludo y presentación corporativa según canal y emisión / recepción\n",
    "* Si en el transcurso de la conversación cambia el interloculor se presenta nuevamente\n",
    "* Continúa con el protocolo de presentación aunque el cliente conteste a su saludo\n",
    "* Comienza la presentación en un tiempo inferior a 3 seg tras recibir la llamada\n",
    "* Está preparado para la siguiente llamada. Sensación positiva. Su presentación es natural, entendible y comercial\n",
    "* El cliente interrumpe la presentación del asesor para exponer directamente el argumento\n",
    "* Por causas ajenas al asesor no se pueda entender la presentación\n",
    "0 si cumple:\n",
    "* No emplea presentación corporativa\n",
    "* Saludo coloquial, falta de concentración.\n",
    "* Si el transcurso de la conversación cambia el interloculor no vuelve a presentarse\n",
    "* Denota cansancio, apatía en el saludo, repetitividad. Su presentación es mecánica, difícil de entender y/o poco comercial.\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_identificaciónDelCliente (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Identifica de forma correcta al cliente o interlocutor.\n",
    "* Pregunta y confirma todos los datos establecidos por protocolo en la política de seguridad\n",
    "* No facilitar información a no tomadores de las pólizas\n",
    "* No ofrece informacion que por motivos de seguridad (LOPD) Generali no desea divulgar\n",
    "0 si cumple:\n",
    "* No identifica al cliente o interlocutor\n",
    "* No pasa pólitica de seguridad \n",
    "* Facilita informacion a no tomador\n",
    "* Ofrece información que por motivos de seguridad Generali no desea divulgar\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_despedidaCorporativa  (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Antes de finalizar la llamada pregunta al cliente si puede ofrecerle ayuda adicional con fórmulas como ¿puedo ayudarle en algo más? ¿puedo facilitarle alguna información adicional?\n",
    "* Cuando se corta la llamada\n",
    "0 si cumple:\n",
    "* No ofrece ayuda adicional\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_ofreceAyudaAdicional (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Utiliza la despedida/s establecida para cada canal y servicio\n",
    "* Su despedida es natural y entendible           \n",
    "* Cuando se corta la llamada\n",
    "0 si cumple:\n",
    "* No utiliza la despedida establecida.\n",
    "* Despedida coloquial.\n",
    "* Su despedida es mecánica y difícil de entender.\n",
    "* No se despide, permaneciendo en silencio al finalizar la llamada.\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_correcciónGramatical  (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Se expresa de forma gramaticalmente correcta\n",
    "* No emplea dequeísmos, laísmos, leísmos,…\n",
    "0 si cumple:\n",
    "* Utiliza dequeísmos, laísmos, leísmos,… \n",
    "* Emplea expresiones gramaticalmente incorrectas\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_expresiónOral (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Se expresa de forma clara, precisa, ordenada, concisa y formal, adaptándose al nivel del cliente. \n",
    "* Demuestra tener fluidez verbal y facilidad para emplear el lenguaje durante el transcurso de la conversación\n",
    "0 si cumple:\n",
    "* Se expresade forma imprecisa y desordenada. \n",
    "* Utiliza palabras de relleno, poco claras o frases hechas. \n",
    "* Utiliza palabras o expresiones que el interlocutor no entiende. \n",
    "* No demuestra tener fluidez verbal\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_Vocabulario (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Utiliza un vocabulario rico, correcto, positivo, comercial.\n",
    "* Omite muletillas, jerga, palabras negras, negativas, diminutivos, superlativos, palabras imprecisas, etc. \n",
    "* No emplea términos de procedimientos internos o tecnicísmos* Se expresa de forma clara, precisa, ordenada, concisa y formal, adaptándose al nivel del cliente. \n",
    "* Demuestra tener fluidez verbal y facilidad para emplear el lenguaje durante el transcurso de la conversación\n",
    "0 si cumple:\n",
    "* Su vocabulario es pobre, incorrecto, negativo o poco comercial. \n",
    "* Utiliza: Palabras negras (problema), Palabras negativas (no), Palabras dubitativas (quizás), Palabras imprecisas (quizás, más o menos...),  Muletillas, argot, coloquialismos, Frases hechas, Diminutivos (un momentito), Superlativos, Tecnicismos y  expresiones propias del departamento.\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_entonaciónModulación (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Evita la monotonía, varia el ritmo, expresividad.\n",
    "* Modula y entona la voz adaptándola a cada una de las frases de la conversación\n",
    "* Conserva siempre un volumen medio, ni grita ni susurra\n",
    "0 si cumple:\n",
    "* No modula (altos/bajos), es monocorde, cansino, apático, tiene musicalidad, etc., lo que provoca que el interlocutor tenga que realizar un esfuerzo para comprender el mensaje emitido por el asesor\n",
    "* Grita o susurra, sube el volumen para enfatizar\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_correctaArticulaciónElocuciónAdecuada (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Evita la monotonía, varia el ritmo, expresividad.\n",
    "* Modula y entona la voz adaptándola a cada una de las frases de la conversación\n",
    "* Conserva siempre un volumen medio, ni grita ni susurra\n",
    "0 si cumple:\n",
    "* No modula (altos/bajos), es monocorde, cansino, apático, tiene musicalidad, etc., lo que provoca que el interlocutor tenga que realizar un esfuerzo para comprender el mensaje emitido por el asesor\n",
    "* Grita o susurra, sube el volumen para enfatizar\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_sonrisaTelefónica (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Emplea la sonrisa siempre que es posible. \n",
    "* Mantiene una actitud positiva, un tono alegre.\n",
    "0 si cumple:\n",
    "* La situación permite sonrisa y no se percibe\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_FormulasDeCortesía (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Aparecen claras muestras de deferencia y respeto por el interlocutor. \n",
    "* Hace uso de fórmulas de cortesía durante el transcurso de la conversación y al interrogar al cliente. \n",
    "* Pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestica o perjuicio al cliente\n",
    "0 si cumple:\n",
    "* No hace uso de fórmulas de cortesía durante el transcurso de la conversación y/o al interrogar al cliente . \n",
    "* Empleo de imperativos. \n",
    "* No pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestio o perjuicio al cliente\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_noInterrumpir (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Aparecen claras muestras de deferencia y respeto por el interlocutor. \n",
    "* Hace uso de fórmulas de cortesía durante el transcurso de la conversación y al interrogar al cliente. \n",
    "* Pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestica o perjuicio al cliente\n",
    "0 si cumple:\n",
    "* No hace uso de fórmulas de cortesía durante el transcurso de la conversación y/o al interrogar al cliente . \n",
    "* Empleo de imperativos. \n",
    "* No pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestio o perjuicio al cliente\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_Esperas (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "a) Justifica la espera:\n",
    "* Se avisa al cliente para mantenerle en espera \n",
    "* Utiliza las esperas de forma correcta, sólo si es necesario y en los casos de consulta al supervisor o transferencia de la llamada. \n",
    "* Cuando tiene que transferir la llamada, informa previamente de ello y emplea el argumento correcto para informar de la misma. \n",
    "* Justifica el motivo de la espera con el argumento correcto\n",
    "b) Retoma la llamada:\n",
    "* Cuando tiene que dejar al cliente en espera, retoma la llamada cada 30 seg\n",
    "* Emplea un argumento correcto cada vez que retoma al cliente informándole de la gestión\n",
    "* Presenta disculpas por haberle mantenido en espera y retoma siguiendo el protocolo establecido (Sr. Martínez, gracias por su espera) * Cuando no se da la circunstancia de dejar al interlocutor en espera en ningún momento.\n",
    "0 si cumple:\n",
    "a) Justifica la espera:\n",
    "* No informa al cliente para mantenerle a la espera. \n",
    "* No justifica la espera, no informa previamente de la necesidad de la msma ni justifica el motivo con un argumento correcto.\n",
    "b) Retoma la llamada:\n",
    "* No retoma la llamada periódicamente, cada 30 seg.\n",
    "* No retoma de forma correcta, lo hace sin agradecer la espera y sin ningún argumento, exponiendo directamente la solución.\n",
    "* Cuando tiene que transferir no informa y/o emplea un argumento incompleto/incorrecto para informar de la transferencia.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_controlDeLosSilencios (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Evita silencios innecesarios.\n",
    "* Evita el efecto \"tunel oscuro\": nos quedamos sin argumento y no sabemos que contestar al cliente, mantenemos en espera mucho tiempo mientras gestionamos sin retomar y justificar la espera\n",
    "0 si cumple:\n",
    "* Silencios innecesarios a lo largo de la conversación.\n",
    "* Se queda en silencio y sin argumentos, o se mantiene en silencio prolongado mientras gestiona sin justificar\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_escuchaActiva (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Manifiesta interés y atención por lo que le plantean, se adapta a la psicología del interlocutor.\n",
    "* Comprende cualquier actitud. \n",
    "* Hace sentir al interlocutor que está prestando la máxima atención a sus explicaciones. \n",
    "* Interviene evitando incómodos silencios durante el transcurso de la conversación. \n",
    "* Cada vez que practica la escucha activa lo hace de forma natural.\n",
    "0 si cumple:\n",
    "* No se percibe esfuerzo en la atención ni interés por las explicaciones del interlocutor. \n",
    "* No entiende las reacciones y replica con las mismas formas. \n",
    "* Se producen incómodos silencios durante el transcurso de la conversación. \n",
    "* Cada vez que practica la escucha activa a lo largo de la conversación lo hace de forma mecánica.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_necesidadDelCliente (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Entiende la posición del interlocutor, empatía absoluta\n",
    "* Disponibilidad para la ayuda\n",
    "* Realiza un correcto sondeo (recepción) / Exposición del mensaje (emisión)\n",
    "* Hace preguntas claves para obtener la información necesaria para dirigir la llamada.\n",
    "* Reformula datos aportados por el cliente\n",
    "* Reconstruye y sintetiza acuerdos o datos. Lo hace a lo largo de la conversación\n",
    "0 si cumple:\n",
    "* Revela excesiva indiferencia y frialdad\n",
    "* No se esfuerza en averiguar lo que le plantean, sólo indaga lo mínimo. \n",
    "* No ofrece distintas alternativas al tema planteado ni orienta al cliente hacia la que más se adecua a sus necesidades. \n",
    "* No expone de forma estructurada.\n",
    "* No repite los acuerdos.\n",
    "* No aclara las ideas difusas\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_personalizaciónEnElTrato (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Se dirige a la persona como un interlocutor conocido (no es uno más). \n",
    "* Una vez identificado el interlocutor (sea o no el titular) se dirige a él utilizando el tratamiento Sr./Sra. seguido del apellido o D./Dña. seguido del nombre. En caso de que el apellido sea malsonante o difícil de pronunciar se optará por el tratamiento D/Dña. \n",
    "* Siempre que retoma una llamada o tiene que llamar la atención del interlocutor se dirige utilizando el protocolo establecidido (Sr/Sra. D/Dña). \n",
    "* Siempre utiliza el tratamiento de Usted al dirigirse al cliente, salvo que expresamente lo solicite el cliente\n",
    "0 si cumple:\n",
    "* Da la impresión de no saber con quien habla.\n",
    "* Identificado el interlocutor no hace uso del tratamiento correspondiente. \n",
    "* Al retonar la llamada o llamar la atención del interlocutor no lo hace utilizando el tratamiento correspondiente, sino de forma incorrecta y/o coloquial\n",
    "* Tutea al cliente cuando el no lo solicite.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_direccionDeLaLlamada (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Sabe dirigir la llamada\n",
    "* Lleva el control de la conversación, plantea alternativas\n",
    "* Adopta una actitud segura, dirigiendo la conversación con el fin de que el cliente confie plenamente en el servicio. Firmeza y seguridad en las afirmaciones\n",
    "* Seguridad en las reacciones y respuestas\n",
    "* Cambia la percepción negativa del cliente a través de argumentos.\n",
    "0 si cumple:\n",
    "* No dirige la llamada siendo el cliente el que establece las pautas durante la conversación. \n",
    "* No propone alternativas.\n",
    "* Se penalizan los monólogos\n",
    "* Transmite inseguridad y hace que el cliente no confie plenamente en el servicio\n",
    "* Utiliza expresiones o palabras dubitativas de forma reiterada.\n",
    "* Titubea dejando frases a medias de forma constante.\n",
    "* No logra convencer.\n",
    "* Silencios breves que muestran nervios o inseguridad.\n",
    "* Consulta constantemente cada pregunta que le plantea el cliente.\n",
    "* También se considera incorrecto el exceso de seguridad, es decir, cuando el asesor adopta una actitud prepotente y agresiva hacia al cliente\n",
    "* Mal tratamiento de objeciones. No sabe tratar las objeciones. No las rebate o lo hace sin convicción, siendo dubitarivo, impreciso, etc. \n",
    "* Permanece en silencio ante las objecciones del cliente.\n",
    "* Mantiene el tono negativo de un cliente.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_imagenDeLaEmpresa (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Aporta información, buena imagen de la compañía y de sus productos y servicios. \n",
    "* Proyecta una imagen positiva de la empresa, buscando tanto el beneficio del cliente como el de la empresa. \n",
    "* Asume las responsabilidades derivadas del posible error de cualquier compañero como si hubiera sido propio.\n",
    "0 si cumple:\n",
    "* Crea una mala imagen de la empresa. \n",
    "* Se muestra indiferente ante el beneficio de Generali y del cliente, proyectando una imagen negativa de la empresa.\n",
    "* Se excusa en los compañeros o en otros departamentos\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_empatia (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Entiende la posición del interlocutor, empatía absoluta\n",
    "0 si cumple:\n",
    "* Revela excesiva indiferencia y frialdad\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_correctoUsoAplicacionesSistemas (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Utiliza las diferentes aplicaciones de forma correcta para su consulta o la gestión de solicitudes de los clientes.\n",
    "* Incidencias en los sistemas\n",
    "0 si cumple:\n",
    "* No realiza un uso correcto de las aplicaciones disponibles.\n",
    "* No transfiere de forma correcta (cuándo proceda). \n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_conocimientoAplicaciónProtocolosProcedimientos (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Conoce los procedimientos y protocolos y los aplica de forma correcta en la llamada y/o gestión.\n",
    "0 si cumple:\n",
    "* No conoce o no aplica los procedimientos establecidos para cada llamada, tipo de solicitud, etc. \n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_clasificaciones (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Tipifica la llamada y lo hace de forma correcta en el aplicativo. La tipificación debe ajustarse al contenido de la llamada (incluyendo observaciones de la llamada en la tipificación)\n",
    "* Incidencias en los sistemas\n",
    "0 si cumple:\n",
    "* No tipifica o tipifica de forma incorrecta la llamada\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_resolucion (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Resuelve una situación que puede concluir por si mismo evitando llamadas posteriores del cliente por el mismo motivo\n",
    "* Si la situación no puede resolverse online, transfiere la llamada / gestión al departamento correcto siguiendo el protocolo marcado\n",
    "* Confirma con el cliente la gestión realizada\n",
    "* Hace una reformulación final resumen de todo lo gestionado en la llamada.                                            \n",
    "* Cuando por incidencia técnica en los sistemas no puede resolver en la llamada\n",
    "0 si cumple:\n",
    "* No se esfuerza en encontrar una solución a su alcance\n",
    "* No verifica la comprensión del cliente\n",
    "* Actitud pasiva, indiferente, despreocupación\n",
    "* No confirma con el cliente la gestión realizada\n",
    "* No realiza ninguna reformulación final, resumen de los acuerdos alcanzados con el mismo\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc3905",
   "metadata": {},
   "source": [
    "Generate the JSON file for the fine-tuning process, selecting only the items that are retained in the filtered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a7fac1a-7583-4ca3-af99-2b451215e75f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def createQuery(target_file):\n",
    "\n",
    "    try:\n",
    "        # Get the responses based on the condition\n",
    "        file_path = \"../output/\" + str(target_file) + \".txt\"\n",
    "        responses = df.loc[df['File'] == target_file, 'component_1':'component_24'].values.tolist()[0]\n",
    "\n",
    "        dialogs = [\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_acogidaCorporativa(file_path) + \" ### Response: La valoración de este item es \" + str(responses[0])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_identificaciónDelCliente(file_path) + \" ### Response: La valoración de este item es \" + str(responses[1])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_despedidaCorporativa(file_path) + \" ### Response: La valoración de este item es \" + str(responses[2])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_ofreceAyudaAdicional(file_path) + \" ### Response: La valoración de este item es \" + str(responses[3])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_correcciónGramatical(file_path) + \" ### Response: La valoración de este item es \" + str(responses[4])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_expresiónOral(file_path) + \" ### Response: La valoración de este item es \" + str(responses[5])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_Vocabulario(file_path) + \" ### Response: La valoración de este item es \" + str(responses[6])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_entonaciónModulación(file_path) + \" ### Response: La valoración de este item es \" + str(responses[7])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_correctaArticulaciónElocuciónAdecuada(file_path) + \" ### Response: La valoración de este item es \" + str(responses[8])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_sonrisaTelefónica(file_path) + \" ### Response: La valoración de este item es \" + str(responses[9])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_FormulasDeCortesía(file_path) + \" ### Response: La valoración de este item es \" + str(responses[10])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_noInterrumpir(file_path) + \" ### Response: La valoración de este item es \" + str(responses[11])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_Esperas(file_path) + \" ### Response: La valoración de este item es \" + str(responses[12])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_controlDeLosSilencios(file_path) + \" ### Response: La valoración de este item es \" + str(responses[13])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_escuchaActiva(file_path) + \" ### Response: La valoración de este item es \" + str(responses[14])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_necesidadDelCliente(file_path) + \" ### Response: La valoración de este item es \" + str(responses[15])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_personalizaciónEnElTrato(file_path) + \" ### Response: La valoración de este item es \" + str(responses[16])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_direccionDeLaLlamada(file_path) + \" ### Response: La valoración de este item es \" + str(responses[17])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_imagenDeLaEmpresa(file_path) + \" ### Response: La valoración de este item es \" + str(responses[18])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_empatia(file_path) + \" ### Response: La valoración de este item es \" + str(responses[19])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_correctoUsoAplicacionesSistemas(file_path) + \" ### Response: La valoración de este item es \" + str(responses[20])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_conocimientoAplicaciónProtocolosProcedimientos(file_path) + \" ### Response: La valoración de este item es \" + str(responses[21])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_clasificaciones(file_path) + \" ### Response: La valoración de este item es \" + str(responses[22])},\n",
    "            {\"Inputs\": \"### Instruction: \" + evaluate_resolucion(file_path) + \" ### Response: La valoración de este item es \" + str(responses[23])}\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating dialogs for file {file_path}: {e}\")\n",
    "        dialogs = []\n",
    "        \n",
    "    return dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c1b15bf-00c1-45cb-aa7c-7aa34cdaea87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all the dialogs\n",
    "all_dialogs = []\n",
    "\n",
    "# Create a list of all the 'File' IDs from your DataFrame\n",
    "file_ids = df['File'].tolist()\n",
    "\n",
    "# Iterate through the list of 'File' IDs\n",
    "for file_id in file_ids:\n",
    " \n",
    "    # Call the createQuery function\n",
    "    dialogs = createQuery(file_id)\n",
    "    \n",
    "    # Extend the all_dialogs list with the dialogs from the current file\n",
    "    all_dialogs.extend(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0987c5c4-db68-42b6-883b-3043388056d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specify the file path for the JSON file\n",
    "json_file_path = \"output_file.json\"\n",
    "\n",
    "# Save the 'dialogs' list as a JSON file\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(all_dialogs, json_file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
