{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56ffad1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:white;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<h2>Fine-tune  model implementation</h2>\n",
    "\n",
    "In this Jupyter notebook, which is part of the 'Models' folder, we focus on constructing queries for the fine-tunned models. The process begins by requesting concise outputs, followed by adding evaluation criteria, and finally appending the conversation text to each query. This is done for each conversation individually. We then set up an endpoint to the deployed model and send the queries, continuing until we receive an answer containing either '1' or '0' but not both or neither. If a query is repeated five times without yielding an answer, we record a '2' for that item.\n",
    "\n",
    "After evaluating all items of a conversation, we repeat the querying process two more times. If there is any divergence among the three outputs, we mark the output as '3' to indicate uncertainty. The final results are saved into a .csv file for detailed analysis.\n",
    "\n",
    "To accommodate potential breakdowns during execution, particularly considering AWS's session expiration, we have incorporated a safeguard mechanism. Each time we receive an output vector, we delete the corresponding transcribed text from the folder to prevent redundancy and add the output vector to the .csv. This approach ensures the smooth continuation of the process and maintains the integrity of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b94d5dcd-6289-4e00-af71-7760310b9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import csv\n",
    "import os\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83229f63-eff0-4825-a742-29e3c3b8c56a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_acogidaCorporativa (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Emplea saludo y presentación corporativa según canal y emisión / recepción\n",
    "* Si en el transcurso de la conversación cambia el interloculor se presenta nuevamente\n",
    "* Continúa con el protocolo de presentación aunque el cliente conteste a su saludo\n",
    "* Comienza la presentación en un tiempo inferior a 3 seg tras recibir la llamada\n",
    "* Está preparado para la siguiente llamada. Sensación positiva. Su presentación es natural, entendible y comercial\n",
    "* El cliente interrumpe la presentación del asesor para exponer directamente el argumento\n",
    "* Por causas ajenas al asesor no se pueda entender la presentación\n",
    "0 si cumple:\n",
    "* No emplea presentación corporativa\n",
    "* Saludo coloquial, falta de concentración.\n",
    "* Si el transcurso de la conversación cambia el interloculor no vuelve a presentarse\n",
    "* Denota cansancio, apatía en el saludo, repetitividad. Su presentación es mecánica, difícil de entender y/o poco comercial.\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_identificaciónDelCliente (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Identifica de forma correcta al cliente o interlocutor.\n",
    "* Pregunta y confirma todos los datos establecidos por protocolo en la política de seguridad\n",
    "* No facilitar información a no tomadores de las pólizas\n",
    "* No ofrece informacion que por motivos de seguridad (LOPD) Generali no desea divulgar\n",
    "0 si cumple:\n",
    "* No identifica al cliente o interlocutor\n",
    "* No pasa pólitica de seguridad \n",
    "* Facilita informacion a no tomador\n",
    "* Ofrece información que por motivos de seguridad Generali no desea divulgar\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_despedidaCorporativa  (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Antes de finalizar la llamada pregunta al cliente si puede ofrecerle ayuda adicional con fórmulas como ¿puedo ayudarle en algo más? ¿puedo facilitarle alguna información adicional?\n",
    "* Cuando se corta la llamada\n",
    "0 si cumple:\n",
    "* No ofrece ayuda adicional\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_ofreceAyudaAdicional (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Utiliza la despedida/s establecida para cada canal y servicio\n",
    "* Su despedida es natural y entendible           \n",
    "* Cuando se corta la llamada\n",
    "0 si cumple:\n",
    "* No utiliza la despedida establecida.\n",
    "* Despedida coloquial.\n",
    "* Su despedida es mecánica y difícil de entender.\n",
    "* No se despide, permaneciendo en silencio al finalizar la llamada.\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_correcciónGramatical  (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Se expresa de forma gramaticalmente correcta\n",
    "* No emplea dequeísmos, laísmos, leísmos,…\n",
    "0 si cumple:\n",
    "* Utiliza dequeísmos, laísmos, leísmos,… \n",
    "* Emplea expresiones gramaticalmente incorrectas\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_expresiónOral (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Se expresa de forma clara, precisa, ordenada, concisa y formal, adaptándose al nivel del cliente. \n",
    "* Demuestra tener fluidez verbal y facilidad para emplear el lenguaje durante el transcurso de la conversación\n",
    "0 si cumple:\n",
    "* Se expresade forma imprecisa y desordenada. \n",
    "* Utiliza palabras de relleno, poco claras o frases hechas. \n",
    "* Utiliza palabras o expresiones que el interlocutor no entiende. \n",
    "* No demuestra tener fluidez verbal\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_Vocabulario (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Utiliza un vocabulario rico, correcto, positivo, comercial.\n",
    "* Omite muletillas, jerga, palabras negras, negativas, diminutivos, superlativos, palabras imprecisas, etc. \n",
    "* No emplea términos de procedimientos internos o tecnicísmos* Se expresa de forma clara, precisa, ordenada, concisa y formal, adaptándose al nivel del cliente. \n",
    "* Demuestra tener fluidez verbal y facilidad para emplear el lenguaje durante el transcurso de la conversación\n",
    "0 si cumple:\n",
    "* Su vocabulario es pobre, incorrecto, negativo o poco comercial. \n",
    "* Utiliza: Palabras negras (problema), Palabras negativas (no), Palabras dubitativas (quizás), Palabras imprecisas (quizás, más o menos...),  Muletillas, argot, coloquialismos, Frases hechas, Diminutivos (un momentito), Superlativos, Tecnicismos y  expresiones propias del departamento.\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_entonaciónModulación (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Evita la monotonía, varia el ritmo, expresividad.\n",
    "* Modula y entona la voz adaptándola a cada una de las frases de la conversación\n",
    "* Conserva siempre un volumen medio, ni grita ni susurra\n",
    "0 si cumple:\n",
    "* No modula (altos/bajos), es monocorde, cansino, apático, tiene musicalidad, etc., lo que provoca que el interlocutor tenga que realizar un esfuerzo para comprender el mensaje emitido por el asesor\n",
    "* Grita o susurra, sube el volumen para enfatizar\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_correctaArticulaciónElocuciónAdecuada (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Evita la monotonía, varia el ritmo, expresividad.\n",
    "* Modula y entona la voz adaptándola a cada una de las frases de la conversación\n",
    "* Conserva siempre un volumen medio, ni grita ni susurra\n",
    "0 si cumple:\n",
    "* No modula (altos/bajos), es monocorde, cansino, apático, tiene musicalidad, etc., lo que provoca que el interlocutor tenga que realizar un esfuerzo para comprender el mensaje emitido por el asesor\n",
    "* Grita o susurra, sube el volumen para enfatizar\n",
    "conversación:\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_sonrisaTelefónica (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Emplea la sonrisa siempre que es posible. \n",
    "* Mantiene una actitud positiva, un tono alegre.\n",
    "0 si cumple:\n",
    "* La situación permite sonrisa y no se percibe\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_FormulasDeCortesía (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Aparecen claras muestras de deferencia y respeto por el interlocutor. \n",
    "* Hace uso de fórmulas de cortesía durante el transcurso de la conversación y al interrogar al cliente. \n",
    "* Pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestica o perjuicio al cliente\n",
    "0 si cumple:\n",
    "* No hace uso de fórmulas de cortesía durante el transcurso de la conversación y/o al interrogar al cliente . \n",
    "* Empleo de imperativos. \n",
    "* No pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestio o perjuicio al cliente\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_noInterrumpir (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Aparecen claras muestras de deferencia y respeto por el interlocutor. \n",
    "* Hace uso de fórmulas de cortesía durante el transcurso de la conversación y al interrogar al cliente. \n",
    "* Pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestica o perjuicio al cliente\n",
    "0 si cumple:\n",
    "* No hace uso de fórmulas de cortesía durante el transcurso de la conversación y/o al interrogar al cliente . \n",
    "* Empleo de imperativos. \n",
    "* No pide disculpas en aquellas ocasiones en las que se ha ocasionado alguna molestio o perjuicio al cliente\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_Esperas (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "a) Justifica la espera:\n",
    "* Se avisa al cliente para mantenerle en espera \n",
    "* Utiliza las esperas de forma correcta, sólo si es necesario y en los casos de consulta al supervisor o transferencia de la llamada. \n",
    "* Cuando tiene que transferir la llamada, informa previamente de ello y emplea el argumento correcto para informar de la misma. \n",
    "* Justifica el motivo de la espera con el argumento correcto\n",
    "b) Retoma la llamada:\n",
    "* Cuando tiene que dejar al cliente en espera, retoma la llamada cada 30 seg\n",
    "* Emplea un argumento correcto cada vez que retoma al cliente informándole de la gestión\n",
    "* Presenta disculpas por haberle mantenido en espera y retoma siguiendo el protocolo establecido (Sr. Martínez, gracias por su espera) * Cuando no se da la circunstancia de dejar al interlocutor en espera en ningún momento.\n",
    "0 si cumple:\n",
    "a) Justifica la espera:\n",
    "* No informa al cliente para mantenerle a la espera. \n",
    "* No justifica la espera, no informa previamente de la necesidad de la msma ni justifica el motivo con un argumento correcto.\n",
    "b) Retoma la llamada:\n",
    "* No retoma la llamada periódicamente, cada 30 seg.\n",
    "* No retoma de forma correcta, lo hace sin agradecer la espera y sin ningún argumento, exponiendo directamente la solución.\n",
    "* Cuando tiene que transferir no informa y/o emplea un argumento incompleto/incorrecto para informar de la transferencia.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_controlDeLosSilencios (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Evita silencios innecesarios.\n",
    "* Evita el efecto \"tunel oscuro\": nos quedamos sin argumento y no sabemos que contestar al cliente, mantenemos en espera mucho tiempo mientras gestionamos sin retomar y justificar la espera\n",
    "0 si cumple:\n",
    "* Silencios innecesarios a lo largo de la conversación.\n",
    "* Se queda en silencio y sin argumentos, o se mantiene en silencio prolongado mientras gestiona sin justificar\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_escuchaActiva (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Manifiesta interés y atención por lo que le plantean, se adapta a la psicología del interlocutor.\n",
    "* Comprende cualquier actitud. \n",
    "* Hace sentir al interlocutor que está prestando la máxima atención a sus explicaciones. \n",
    "* Interviene evitando incómodos silencios durante el transcurso de la conversación. \n",
    "* Cada vez que practica la escucha activa lo hace de forma natural.\n",
    "0 si cumple:\n",
    "* No se percibe esfuerzo en la atención ni interés por las explicaciones del interlocutor. \n",
    "* No entiende las reacciones y replica con las mismas formas. \n",
    "* Se producen incómodos silencios durante el transcurso de la conversación. \n",
    "* Cada vez que practica la escucha activa a lo largo de la conversación lo hace de forma mecánica.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_necesidadDelCliente (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Entiende la posición del interlocutor, empatía absoluta\n",
    "* Disponibilidad para la ayuda\n",
    "* Realiza un correcto sondeo (recepción) / Exposición del mensaje (emisión)\n",
    "* Hace preguntas claves para obtener la información necesaria para dirigir la llamada.\n",
    "* Reformula datos aportados por el cliente\n",
    "* Reconstruye y sintetiza acuerdos o datos. Lo hace a lo largo de la conversación\n",
    "0 si cumple:\n",
    "* Revela excesiva indiferencia y frialdad\n",
    "* No se esfuerza en averiguar lo que le plantean, sólo indaga lo mínimo. \n",
    "* No ofrece distintas alternativas al tema planteado ni orienta al cliente hacia la que más se adecua a sus necesidades. \n",
    "* No expone de forma estructurada.\n",
    "* No repite los acuerdos.\n",
    "* No aclara las ideas difusas\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_personalizaciónEnElTrato (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Se dirige a la persona como un interlocutor conocido (no es uno más). \n",
    "* Una vez identificado el interlocutor (sea o no el titular) se dirige a él utilizando el tratamiento Sr./Sra. seguido del apellido o D./Dña. seguido del nombre. En caso de que el apellido sea malsonante o difícil de pronunciar se optará por el tratamiento D/Dña. \n",
    "* Siempre que retoma una llamada o tiene que llamar la atención del interlocutor se dirige utilizando el protocolo establecidido (Sr/Sra. D/Dña). \n",
    "* Siempre utiliza el tratamiento de Usted al dirigirse al cliente, salvo que expresamente lo solicite el cliente\n",
    "0 si cumple:\n",
    "* Da la impresión de no saber con quien habla.\n",
    "* Identificado el interlocutor no hace uso del tratamiento correspondiente. \n",
    "* Al retonar la llamada o llamar la atención del interlocutor no lo hace utilizando el tratamiento correspondiente, sino de forma incorrecta y/o coloquial\n",
    "* Tutea al cliente cuando el no lo solicite.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_direccionDeLaLlamada (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Sabe dirigir la llamada\n",
    "* Lleva el control de la conversación, plantea alternativas\n",
    "* Adopta una actitud segura, dirigiendo la conversación con el fin de que el cliente confie plenamente en el servicio. Firmeza y seguridad en las afirmaciones\n",
    "* Seguridad en las reacciones y respuestas\n",
    "* Cambia la percepción negativa del cliente a través de argumentos.\n",
    "0 si cumple:\n",
    "* No dirige la llamada siendo el cliente el que establece las pautas durante la conversación. \n",
    "* No propone alternativas.\n",
    "* Se penalizan los monólogos\n",
    "* Transmite inseguridad y hace que el cliente no confie plenamente en el servicio\n",
    "* Utiliza expresiones o palabras dubitativas de forma reiterada.\n",
    "* Titubea dejando frases a medias de forma constante.\n",
    "* No logra convencer.\n",
    "* Silencios breves que muestran nervios o inseguridad.\n",
    "* Consulta constantemente cada pregunta que le plantea el cliente.\n",
    "* También se considera incorrecto el exceso de seguridad, es decir, cuando el asesor adopta una actitud prepotente y agresiva hacia al cliente\n",
    "* Mal tratamiento de objeciones. No sabe tratar las objeciones. No las rebate o lo hace sin convicción, siendo dubitarivo, impreciso, etc. \n",
    "* Permanece en silencio ante las objecciones del cliente.\n",
    "* Mantiene el tono negativo de un cliente.\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_imagenDeLaEmpresa (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Aporta información, buena imagen de la compañía y de sus productos y servicios. \n",
    "* Proyecta una imagen positiva de la empresa, buscando tanto el beneficio del cliente como el de la empresa. \n",
    "* Asume las responsabilidades derivadas del posible error de cualquier compañero como si hubiera sido propio.\n",
    "0 si cumple:\n",
    "* Crea una mala imagen de la empresa. \n",
    "* Se muestra indiferente ante el beneficio de Generali y del cliente, proyectando una imagen negativa de la empresa.\n",
    "* Se excusa en los compañeros o en otros departamentos\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_empatia (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Entiende la posición del interlocutor, empatía absoluta\n",
    "0 si cumple:\n",
    "* Revela excesiva indiferencia y frialdad\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_correctoUsoAplicacionesSistemas (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Utiliza las diferentes aplicaciones de forma correcta para su consulta o la gestión de solicitudes de los clientes.\n",
    "* Incidencias en los sistemas\n",
    "0 si cumple:\n",
    "* No realiza un uso correcto de las aplicaciones disponibles.\n",
    "* No transfiere de forma correcta (cuándo proceda). \n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_conocimientoAplicaciónProtocolosProcedimientos (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Conoce los procedimientos y protocolos y los aplica de forma correcta en la llamada y/o gestión.\n",
    "0 si cumple:\n",
    "* No conoce o no aplica los procedimientos establecidos para cada llamada, tipo de solicitud, etc. \n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_clasificaciones (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Tipifica la llamada y lo hace de forma correcta en el aplicativo. La tipificación debe ajustarse al contenido de la llamada (incluyendo observaciones de la llamada en la tipificación)\n",
    "* Incidencias en los sistemas\n",
    "0 si cumple:\n",
    "* No tipifica o tipifica de forma incorrecta la llamada\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string\n",
    "\n",
    "def evaluate_resolucion (file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        conversation = file.read() \n",
    "        \n",
    "    output_string = f\"\"\"La respuesta unicamente debe ser 1 o 0 Sea 1 si el siguiente conversación cumple:\n",
    "* Resuelve una situación que puede concluir por si mismo evitando llamadas posteriores del cliente por el mismo motivo\n",
    "* Si la situación no puede resolverse online, transfiere la llamada / gestión al departamento correcto siguiendo el protocolo marcado\n",
    "* Confirma con el cliente la gestión realizada\n",
    "* Hace una reformulación final resumen de todo lo gestionado en la llamada.                                            \n",
    "* Cuando por incidencia técnica en los sistemas no puede resolver en la llamada\n",
    "0 si cumple:\n",
    "* No se esfuerza en encontrar una solución a su alcance\n",
    "* No verifica la comprensión del cliente\n",
    "* Actitud pasiva, indiferente, despreocupación\n",
    "* No confirma con el cliente la gestión realizada\n",
    "* No realiza ninguna reformulación final, resumen de los acuerdos alcanzados con el mismo\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a99085bd-7b6d-4ad0-b16f-dd9a1616dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createQuery(file_path):\n",
    "    dialogs = [\n",
    "        evaluate_acogidaCorporativa(file_path),\n",
    "        evaluate_identificaciónDelCliente(file_path),\n",
    "        evaluate_despedidaCorporativa(file_path),\n",
    "        evaluate_ofreceAyudaAdicional(file_path),\n",
    "        evaluate_correcciónGramatical(file_path),\n",
    "        evaluate_expresiónOral(file_path),\n",
    "        evaluate_Vocabulario(file_path),\n",
    "        evaluate_entonaciónModulación(file_path),\n",
    "        evaluate_correctaArticulaciónElocuciónAdecuada(file_path),\n",
    "        evaluate_sonrisaTelefónica(file_path),\n",
    "        evaluate_FormulasDeCortesía(file_path),\n",
    "        evaluate_noInterrumpir(file_path),\n",
    "        evaluate_Esperas(file_path),\n",
    "        evaluate_controlDeLosSilencios(file_path),\n",
    "        evaluate_escuchaActiva(file_path),\n",
    "        evaluate_necesidadDelCliente(file_path),\n",
    "        evaluate_personalizaciónEnElTrato(file_path),\n",
    "        evaluate_direccionDeLaLlamada(file_path),\n",
    "        evaluate_imagenDeLaEmpresa(file_path),\n",
    "        evaluate_empatia(file_path),\n",
    "        evaluate_correctoUsoAplicacionesSistemas(file_path),\n",
    "        evaluate_conocimientoAplicaciónProtocolosProcedimientos(file_path),\n",
    "        evaluate_clasificaciones(file_path),\n",
    "        evaluate_resolucion(file_path)]\n",
    "        \n",
    "    return dialogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a97671d6-14da-4c24-a7e1-7204324280c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = \"jumpstart-ftc-meta-textgeneration-llama-2-7b\"\n",
    "\n",
    "\n",
    "def query_endpoint(payload):\n",
    "    client = boto3.client(\"sagemaker-runtime\")\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType=\"application/json\",\n",
    "        Body=json.dumps(payload),\n",
    "        CustomAttributes=\"accept_eula=true\",\n",
    "    )\n",
    "    response = response[\"Body\"].read().decode(\"utf8\")\n",
    "    response = json.loads(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "627a8643-8432-4577-8d20-51f333deec31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_output_vector(dialogs):\n",
    "    output_vector = []  # Initialize an empty list to store the output\n",
    "\n",
    "    for dialog in dialogs:\n",
    "        contains_1 = False\n",
    "        contains_0 = False\n",
    "        \n",
    "        i = 0\n",
    "        while not (contains_1 or contains_0):\n",
    "            payload = {\n",
    "                \"inputs\": dialog, \n",
    "                \"parameters\": {\"max_new_tokens\": 500, \"top_p\": 0.9, \"temperature\": 0.6}\n",
    "            }\n",
    "            result = query_endpoint(payload)[0]\n",
    "            generated_content = result['generated_text'][:50]  # Extract the first 50 characters\n",
    "            print(result['generated_text'][:50])\n",
    "            contains_1 = \"1\" in generated_content\n",
    "            contains_0 = \"0\" in generated_content\n",
    "\n",
    "            if i == 5:  # Break the loop and append '2' after 5 attempts\n",
    "                output_vector.append(2)\n",
    "                break\n",
    "            i += 1\n",
    "            if contains_1 and contains_0:\n",
    "                contains_1 = False\n",
    "                contains_0 = False\n",
    "                \n",
    "        else:  # Append '1' or '0' if found in the generated content\n",
    "            output_vector.append(1 if contains_1 else 0)\n",
    "\n",
    "    return output_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942aff2-9aa8-42a5-973d-d3b1ed835231",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify the directory containing the transcribed files\n",
    "directory_path = \"../output\"\n",
    "\n",
    "# Get a list of all files in the specified directory\n",
    "all_files = [file for file in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, file))]\n",
    "\n",
    "# Process each file\n",
    "for file_name in all_files:\n",
    "    file_path = os.path.join(directory_path, file_name)\n",
    "    dialogs = createQuery(file_path)\n",
    "    print(file_name)\n",
    "    result_vector1 = generate_output_vector(dialogs)\n",
    "    result_vector2 = generate_output_vector(dialogs)\n",
    "    result_vector3 = generate_output_vector(dialogs)\n",
    "    \n",
    "    # Modify the merging strategy\n",
    "    merged_vector = []\n",
    "    for i in range(len(result_vector1)):\n",
    "        if result_vector1[i] == result_vector2[i] == result_vector3[i]:  # All three vectors have the same value\n",
    "            merged_vector.append(result_vector1[i])\n",
    "        else:\n",
    "            merged_vector.append(3)  # Different values in vectors, append 3\n",
    "    print(merged_vector)\n",
    "    \n",
    "    \n",
    "    # Create a CSV file to write the results\n",
    "    csv_file_path = \"output_results_baseline_model_esp_finetune.csv\"\n",
    "    with open(csv_file_path, mode='a', newline='') as csv_file:\n",
    "        fieldnames = ['File', 'Result']  # Define the column headers\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "\n",
    "        # Check if the file is empty, and write the header row if needed\n",
    "        if os.path.getsize(csv_file_path) == 0:\n",
    "            writer.writeheader()\n",
    "\n",
    "        # Write the result to the CSV file\n",
    "        writer.writerow({'File': file_name, 'Result': merged_vector})\n",
    "\n",
    "    # Delete the processed file\n",
    "    os.remove(file_path)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
